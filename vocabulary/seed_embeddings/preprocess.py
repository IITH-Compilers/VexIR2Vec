# Part of the VexIR2Vec Project, under the AGPL V3.0 License. See the
# LICENSE file or <https://www.gnu.org/licenses/> for license information.

""" The intent of this script is to generate entity2id.txt, train2id.txt and relation2id.txt  """

import argparse
import os
from tqdm import tqdm

# cmd: python preprocess.py --tdir=<dir containing triplets> --odir=<dir to store id files>


def getEntityDict(config):
    uniqueWords = set()
    uniqueRel = set()
    print("Getting entities and relations.")
    for f in tqdm(os.listdir(config.tdir)):
        # for f in os.listdir(config.tdir):
        # print('Processing ', f)
        ip = open(os.path.join(str(config.tdir), f), "r")
        content = ip.read()
        sentences = content.split("\n")
        sentences.pop()
        for sentence in sentences:
            en = sentence.strip().split(" ")
            if len(en) == 3:
                uniqueWords.add(en[0])
                uniqueRel.add(en[1])
                uniqueWords.add(en[2])
            else:
                print("Error in file: ", f)
                print(en)
        ip.close()

    eop = open(os.path.join(config.odir, "entity2id.txt"), "w")
    i = 0
    entityDict = {}
    eop.write(str(len(uniqueWords)) + "\n")
    for word in uniqueWords:
        eop.write(str(word) + "\t" + str(i) + "\n")
        entityDict[str(word)] = str(i)
        i += 1
    eop.close()

    rop = open(os.path.join(config.odir, "relation2id.txt"), "w")
    i = 0
    relationDict = {}
    rop.write(str(len(uniqueRel)) + "\n")
    for rel in uniqueRel:
        rop.write(str(rel) + "\t" + str(i) + "\n")
        relationDict[str(rel)] = str(i)
        i += 1
    rop.close()

    return entityDict, relationDict


def createTrain2ID(ed, rd, config):
    op = open(os.path.join(config.odir, "train2id.txt"), "w")
    nol, tstr = 0, ""
    print("\nCreating train2id.txt ...")
    for f in tqdm(os.listdir(config.tdir)):
        ip = open(os.path.join(str(config.tdir), f), "r")
        content = ip.read()
        sentences = content.split("\n")
        sentences.pop()
        for sentence in sentences:
            s = sentence.strip().split(" ")
            if len(s) == 3:
                if s[0] != "":
                    nol += 1

                if s[0] not in ed or s[2] not in ed or s[1] not in rd:
                    print(s[0])
                    print(s[1])
                    print(s[2])

                tstr += (
                    ed[str(s[0])] + "\t" + ed[str(s[2])] + "\t" + rd[str(s[1])] + "\n"
                )
    op.write(str(nol) + "\n")
    op.write(tstr)
    op.close()


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--tdir",
        dest="tdir",
        help="Path of the directory containing triplet files generated by collect tool.",
        required=True,
    )
    parser.add_argument(
        "--odir",
        dest="odir",
        help="Path of the generated directory containing idfiles after preprocessing.",
        required=True,
    )
    config = parser.parse_args()
    config.tdir = os.path.abspath(config.tdir)
    config.odir = os.path.abspath(config.odir)

    try:
        os.mkdir(config.odir)
    except Exception as err:
        print(err)

    ed, rd = getEntityDict(config)
    createTrain2ID(ed, rd, config)

    print("\nFiles are saved at ", config.odir)
